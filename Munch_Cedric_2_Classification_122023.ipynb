{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "YPWPsLTA6PHzzu8NBJiBGc",
     "report_properties": {
      "rowId": "bQVdch3WwH71PERijuXOJf"
     },
     "type": "MD"
    },
    "id": "BVDmPdkgiwsk"
   },
   "source": [
    "# PROJET 10 DATA ANALYST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "k48auDisTvRZsZfKvxjypF",
     "report_properties": {
      "rowId": "oLZfdyjY97Qfpmb939g74j"
     },
     "type": "MD"
    },
    "id": "SuuBTKk3iwso"
   },
   "source": [
    "# OBJECTIF DE CE NOTEBOOK\n",
    "\n",
    "Pour l'Organisation Nationale de lutte Contre le Faux-Monnayage (ONCFM), nous devons produire :\n",
    "\n",
    "- Une analyse descriptive des données, notamment la répartition des dimensions des billets, le nombre de vrais / faux billets, etc.\n",
    "- Une détection automatisée des faux billets à partir des dimensions de ces derniers. Les méthodes à utiliser sont la régression logistique et k-means avec une matrice de confusion pour évaluer les performances des modèles. Une fois la phase d'entrainement et de test achevée, l'algorithme devra être capable de prédire si un billet est vrai ou faux.\n",
    "\n",
    "Glossaire :\n",
    "- diagonal : la diagonale du billet (en mm)\n",
    "- height_left : la hauteur du billet (mesurée sur le côté gauche, en mm)\n",
    "- height_right : la hauteur du billet (mesurée sur le côté droit, en mm)\n",
    "- length : la longueur du billet (en mm)\n",
    "- margin_low : la marge entre le bord inférieur du billet et l'image de celui-ci (en mm)\n",
    "- margin_up : la marge entre le bord supérieur du billet et l'image de celui-ci (en mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "huuuZ9nVEfTyGWBHbQ8VgQ",
     "report_properties": {
      "rowId": "KcHwtHqP2KarZqESgS5Cuv"
     },
     "type": "MD"
    },
    "id": "bUeH7jbOiwss"
   },
   "source": [
    "## Etape 1 - Importation des librairies et chargement des fichiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "WUgzpCrtz6qvTWeMcwleCe",
     "report_properties": {
      "rowId": "QPTiDox9sGkHkQFnuuMVVz"
     },
     "type": "MD"
    },
    "id": "pCmIR_wtiwsu"
   },
   "source": [
    "## 1.1 - Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "PBnfkRJEuh40fJxLPsn3ZG",
     "report_properties": {
      "rowId": "LEAuwO1pfiygv0Qy8MKwvF"
     },
     "type": "CODE"
    },
    "executionInfo": {
     "elapsed": 3428,
     "status": "ok",
     "timestamp": 1688211938806,
     "user": {
      "displayName": "Tehaniii",
      "userId": "03067073566435797809"
     },
     "user_tz": -120
    },
    "id": "tGnFLpXziwsv",
    "outputId": "504834a0-ff06-49ab-b51d-bef4e9907a22"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "#Importation des librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, f1_score, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import NearestCentroid, KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import scipy.stats as ss\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.pipeline import Pipeline\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement de la librairie graphique\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "sepiokARAir2xuLksAdLsK",
     "report_properties": {
      "rowId": "jsLdri6gPJ7yy6O3enpU4e"
     },
     "type": "MD"
    },
    "id": "1VxbQzPEiwsw"
   },
   "source": [
    "## 1.2 - Chargement du fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": false,
     "hide_output_from_viewers": false,
     "node_id": "eKALxcS4HU8fox5dd9w3Ha",
     "report_properties": {
      "rowId": "F6iF3THpMlmGFJP1AGoMzN"
     },
     "type": "CODE"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1688211938808,
     "user": {
      "displayName": "Tehaniii",
      "userId": "03067073566435797809"
     },
     "user_tz": -120
    },
    "id": "YPfRBY_Eiwsy"
   },
   "outputs": [],
   "source": [
    "#Importation du fichier population.csv en mettant l'index sur 'Zone'\n",
    "billet = pd.read_csv('./Data_transformed/billets_compl.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage des dimensions et de leurs types\n",
    "display(billet.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Affichage d'un échantillon\n",
    "display(billet.sample(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 2 - Split des données et Centrage, Reduction (Scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 - Split des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sélection des variables explicatives et de la variable à expliquer\n",
    "billet_y = billet['is_genuine']\n",
    "billet_X = billet.drop('is_genuine', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 - Centrage et Réduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciation du Scaler\n",
    "std_scale = preprocessing.StandardScaler()\n",
    "\n",
    "#Entrainement\n",
    "std_scale.fit(billet_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformation\n",
    "billet_X_scaled = std_scale.transform(billet_X)"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Remettre les données centrées/réduites dans un dataframe\n",
    "billet_X_scal = pd.DataFrame(billet_X_scaled, columns=billet_X.columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Pour vérifier que le centrage/réduction s'est bien passé\n",
    "display(pd.DataFrame(billet_X_scal).describe().round(2).iloc[1:3:, : ])"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Concaténation des données centrées/réduites avec la variable à expliquer\n",
    "billet_scaled = pd.concat([billet_y, billet_X_scal], axis=1)\n",
    "\n",
    "display(billet_scaled.sample(10))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Etape 3 - Classification et clustering"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.1 - Train/Test Split"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "y = billet_scaled['is_genuine']\n",
    "X = billet_scaled.drop('is_genuine', axis=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Séparation des données en train et test avec stratification pour conserver la proportion de vrais/faux billets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)\n",
    "display(X_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.2 - Dummy model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Calcul du score du modèle Dummy -> Null Accuracy\n",
    "strategies = ['most_frequent', 'stratified', 'uniform']#, 'constant']\n",
    "test_scores = []\n",
    "\n",
    "for s in strategies:\n",
    "    if s =='constant':\n",
    "        dclf = DummyClassifier(strategy = s, random_state = 0, constant ='M')\n",
    "    else:\n",
    "        dclf = DummyClassifier(strategy = s, random_state = 0)\n",
    "    dclf.fit(X_train, y_train)\n",
    "    score = dclf.score(X_test, y_test)\n",
    "    test_scores.append(score)\n",
    "\n",
    "test_scores = [round(aa, 4) for aa in test_scores]\n",
    "print(\"Meilleurs scores des Dummy models : \", test_scores)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3 - Classification (supervisée) : Logistic Regression"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3.1 - Learning curve pour déterminer le nombre d'individus optimal par Kfold"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# TODO : faire la learning curve avec le train set et non le dataset complet"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3.2 - Détermination du nombre de variables explicatives à retenir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RFECV ne fournissant pas les scores du Train set, nous allons utiliser la GridSearchCV pour tester les différentes combinaisons de variables explicatives et ainsi déterminer le nombre de variables explicatives à retenir."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Définition du dictionnaire des variables explicatives à tester\n",
    "hyper_params = [{'n_features_to_select': list(range(1, 7))}]\n",
    "\n",
    "#Instanciation du modèle et de la Recursive Feature Elimination (RFE)\n",
    "lr = LogisticRegression(random_state=0)\n",
    "rfe = RFE(lr)\n",
    "\n",
    "#Instanciation de la GridSearchCV\n",
    "model_cv = GridSearchCV(estimator = rfe,\n",
    "                        param_grid = hyper_params,\n",
    "                        scoring= 'accuracy',\n",
    "                        cv = 5, #Par défaut StratifiedKFold quand l'estimateur est un classifieur\n",
    "                        verbose = 1,\n",
    "                        return_train_score=True)\n",
    "\n",
    "#Fit de la GridSearchCV\n",
    "model_cv.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Résultats de la GridSearchCV\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "#Sélection des colonnes utiles\n",
    "cols = [i for i in cv_results.columns if not i.startswith('split') and not i.endswith('time')]\n",
    "cv_results = cv_results.loc[:, cols]\n",
    "\n",
    "display(cv_results)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Affichage de la contribution des variables explicatives à la performance du modèle\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_features_to_select\"], cv_results[\"mean_train_score\"])\n",
    "\n",
    "plt.xlabel('Nombre de variables explicatives')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Contribution des variables explicatives à la performance du modèle')\n",
    "plt.legend(['validation score', 'train score'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3.3 - Détermination des variables explicatives à retenir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Instanciation du modèle\n",
    "lr = LogisticRegression(random_state=0)\n",
    "\n",
    "#Instanciation de la Recursive Feature Elimination (RFE) et fit\n",
    "rfecv_lr = RFECV(estimator=lr,\n",
    "              cv=4,\n",
    "              scoring='accuracy')\n",
    "\n",
    "rfecv_lr.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Sélection dans le train set des variables explicatives retenues par la RFE\n",
    "X_train_rfecv = X_train.iloc[:, rfecv_lr.support_]\n",
    "\n",
    "display(X_train_rfecv.sample(10))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3.4 - Détermination du paramètre de régularisation C"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Définition du dictionnaire des variables explicatives à tester\n",
    "hyper_params = [{'C': [0.1, 1, 10, 20, 30, 40, 50, 60, 70, 80]}]\n",
    "                 #'penalty': ['l1', 'l2'],\n",
    "                 #'max_iter': [100, 200, 300, 400, 500],\n",
    "                 #'n_jobs': [-1]}]\n",
    "\n",
    "#Instanciation du modèle et de la Recursive Feature Elimination (RFE)\n",
    "lr = LogisticRegression(random_state=0)\n",
    "\n",
    "#Instanciation de la GridSearchCV\n",
    "model_cv = GridSearchCV(estimator = lr,\n",
    "                        param_grid = hyper_params,\n",
    "                        scoring= 'accuracy',\n",
    "                        cv = 5, #Par défaut StratifiedKFold quand l'estimateur est un classifieur\n",
    "                        verbose = 1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)\n",
    "\n",
    "#Fit de la GridSearchCV\n",
    "model_cv.fit(X_train_rfecv, y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Résultats de la GridSearchCV\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "#Sélection des colonnes utiles\n",
    "cols = [i for i in cv_results.columns if not i.startswith('split') and not i.endswith('time')]\n",
    "cv_results = cv_results.loc[:, cols]\n",
    "\n",
    "display(cv_results)\n",
    "print(\"Meilleur Hyper-paramètre : \", model_cv.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Affichage de la contribution des variables explicatives à la performance du modèle\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(cv_results[\"param_C\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_C\"], cv_results[\"mean_train_score\"])\n",
    "\n",
    "plt.xlabel('Force de la Régularisation')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Efficacité de la Régularisation dans la performance du modèle')\n",
    "plt.legend(['validation score', 'train score'], loc='lower right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.3.5 - Validation sur le Test set, Matrice de confusion  et F1 Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Instanciation du modèle\n",
    "lr = LogisticRegression(random_state=0, C=30)\n",
    "\n",
    "#Fit du modèle\n",
    "model_lr = lr.fit(X_train_rfecv, y_train)\n",
    "print(\"Train set Accuracy : \", round(model_lr.score(X_train_rfecv, y_train), 4))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Fonction pour le calcul de l'accuracy score (prédiction inversée en cas d'apprentissage non supervisé avec Target inversée)\n",
    "def acc(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    if accuracy < 0.5:\n",
    "        #Inversion des prédictions en cas d'apprentissage non supervisé avec Target inversée\n",
    "        y_pred = (~y_pred.astype(bool)).astype(int)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    print(\"Accuracy : \",round(accuracy,4))\n",
    "    return y_pred"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Sélection dans le Test set des variables explicatives retenues par la RFECV\n",
    "X_test_rfecv = X_test.iloc[:, rfecv_lr.support_]\n",
    "\n",
    "y_pred_lr = model_lr.predict(X_test_rfecv)\n",
    "\n",
    "#Calcul de l'accuracy score et inversion des prédictions en cas d'apprentissage non supervisé avec Target inversée\n",
    "y_pred_lr = acc(y_test, y_pred_lr)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Matrice de confusion et F1 score**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Matrice de confusion\n",
    "conf_mat = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(conf_mat, annot=True, cbar=None, cmap='Reds', fmt='.0f')\n",
    "\n",
    "plt.ylabel('Réel')\n",
    "plt.xlabel('Prévision');\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_lr, digits=4))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4 - Clustering (non supervisé) : K-Means "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4.1 - Détermination des variables explicatives à retenir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous avons pu remarquer dans le Notebook précédent que les variables explicatives ne sont pas fortement corrélées entre elles (mis à part le coeff de Pearson entre 'margin_low' et 'length' = -0.67). Nous allons donc utiliser toutes les variables explicatives pour le K-Means."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.4.2 - Validation sur le Test set, Matrice de confusion et F1 Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Instanciation et entrainement de l'estimateur\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)\n",
    "kmeans.fit(X_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Extraction des labels\n",
    "y_pred_km_train = kmeans.labels_"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Calcul de l'accuracy score et inversion des prédictions en cas d'apprentissage non supervisé avec Target inversée\n",
    "y_pred_km_train = acc(y_train, y_pred_km_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Prédiction sur le test set\n",
    "y_pred_km_test = kmeans.predict(X_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Calcul de l'accuracy score et inversion des prédictions en cas d'apprentissage non supervisé avec Target inversée\n",
    "y_pred_km_test = acc(y_test, y_pred_km_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Matrice de confusion et F1 score**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Matrice de confusion\n",
    "conf_mat = confusion_matrix(y_test, y_pred_km_test)\n",
    "sns.heatmap(conf_mat, annot=True, cbar=None, cmap='Reds', fmt='.0f')\n",
    "\n",
    "plt.ylabel('Réel')\n",
    "plt.xlabel('Prévision');\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Calcul du F1 score\n",
    "print(classification_report(y_test, y_pred_km_test, digits=4))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.5 - Classification (supervisé) : K-Nearest Neighbors \n",
    "- Learning curve sur le nombre d'individus optimal pour le train set\n",
    "- GridSearchCV pour trouver le nombre de voisins optimal sur le train set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.5.1 - Détermination des variables explicatives à retenir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous avons pu remarquer dans le Notebook précédent que les variables explicatives ne sont pas fortement corrélées entre elles (mis à part le coeff de Pearson entre 'margin_low' et 'length' = -0.67). Nous allons donc utiliser toutes les variables explicatives pour le K-NN."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.5.2 - Détermination du nombre de voisins optimal"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Définition du dictionnaire des variables explicatives à tester\n",
    "hyper_params = [{'n_neighbors': list(range(1, 51))}]\n",
    "\n",
    "#Instanciation du modèle et de la Recursive Feature Elimination (RFE)\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "#Instanciation de la GridSearchCV\n",
    "model_cv = GridSearchCV(estimator = knn,\n",
    "                        param_grid = hyper_params,\n",
    "                        scoring= 'accuracy',\n",
    "                        cv = 5, #Par défaut StratifiedKFold quand l'estimateur est un classifieur\n",
    "                        verbose = 1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)\n",
    "\n",
    "#Fit de la GridSearchCV\n",
    "model_cv.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Résultats de la GridSearchCV\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "#Sélection des colonnes utiles\n",
    "cols = [i for i in cv_results.columns if not i.startswith('split') and not i.endswith('time')]\n",
    "cv_results = cv_results.loc[:, cols]\n",
    "\n",
    "display(cv_results)\n",
    "print(\"Meilleur Hyper-paramètre : \", model_cv.best_params_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Affichage de la contribution des variables explicatives à la performance du modèle\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.plot(cv_results[\"param_n_neighbors\"], cv_results[\"mean_test_score\"])\n",
    "plt.plot(cv_results[\"param_n_neighbors\"], cv_results[\"mean_train_score\"])\n",
    "\n",
    "plt.xlabel('Nombre de voisins')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Influence du nombre de voisins dans la performance du modèle')\n",
    "plt.legend(['validation score', 'train score'], loc='lower right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.5.3 - Validation sur le Test set, Matrice de confusion et F1 Score"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Instanciation du modèle\n",
    "knn = KNeighborsClassifier(n_neighbors=7, n_jobs=-1)\n",
    "\n",
    "#Fit du modèle\n",
    "model_knn = knn.fit(X_train, y_train)\n",
    "print(\"Train set Accuracy : \", round(model_knn.score(X_train, y_train), 4))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Prévision sur le test set\n",
    "y_pred_knn = model_knn.predict(X_test)\n",
    "\n",
    "#Calcul de l'accuracy score et inversion des prédictions en cas d'apprentissage non supervisé avec Target inversée\n",
    "y_pred_knn = acc(y_test, y_pred_knn)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Matrice de confusion et F1 score**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Matrice de confusion\n",
    "conf_mat = confusion_matrix(y_test, y_pred_knn)\n",
    "sns.heatmap(conf_mat, annot=True, cbar=None, cmap='Reds', fmt='.0f')\n",
    "\n",
    "plt.ylabel('Réel')\n",
    "plt.xlabel('Prévision');\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred_knn, digits=4))"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3.6 - Création d'un Pipeline et export du binaire du modèle"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "En regardant le F1 score des faux billets des différents modèles, nous pouvons voir que le régression logistique est le modèle qui a le meilleur score. Nous allons donc créer un pipeline avec ce modèle et exporter le binaire du modèle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "quant_cols = list(billet_X.iloc[:, rfecv_lr.support_])\n",
    "\n",
    "quant_pipeline = Pipeline(steps=[\n",
    "    ('scale', preprocessing.StandardScaler())\n",
    "    ])\n",
    "\n",
    "col_trans = ColumnTransformer(transformers=[\n",
    "    ('quant_pipeline',quant_pipeline,quant_cols)],\n",
    "    remainder='passthrough',\n",
    "    n_jobs=-1)\n",
    "\n",
    "logreg = LogisticRegression(random_state=0, C=30)\n",
    "\n",
    "logreg_pipeline = Pipeline(steps=[\n",
    "    ('col_trans', col_trans),\n",
    "    ('model', logreg)\n",
    "    ])\n",
    "\n",
    "display(logreg_pipeline)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "billet_X_pipe = billet_X[quant_cols].copy()\n",
    "\n",
    "#Séparation des données en train et test avec stratification pour conserver la proportion de vrais/faux billets\n",
    "X_train_pipe, X_test_pipe, y_train_pipe, y_test_pipe = train_test_split(billet_X_pipe, billet_y, test_size=0.2, random_state=0, stratify=y)\n",
    "display(X_train_pipe)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Fit du pipeline\n",
    "logreg_pipeline.fit(X_train_pipe, y_train_pipe)\n",
    "\n",
    "score = logreg_pipeline.score(X_test_pipe, y_test_pipe)\n",
    "print(\"Test set accuracy : \", score) # model accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous retrouvons bien le même score que précédemment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#y_pred_pipe = logreg_pipeline.predict(X_test_pipe)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Save pipeline to file \"pipe.joblib\"\n",
    "joblib.dump(logreg_pipeline,\"./logreg_pipeline.joblib\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lr_pipeline = joblib.load(\"./logreg_pipeline.joblib\")\n",
    "y_pred_pipe = lr_pipeline.predict(X_test_pipe)\n",
    "display(y_pred_pipe)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "datalore": {
   "base_environment": "default",
   "computation_mode": "JUPYTER",
   "package_manager": "pip",
   "packages": [],
   "report_row_ids": [
    "bQVdch3WwH71PERijuXOJf",
    "oLZfdyjY97Qfpmb939g74j",
    "8JGXqNfVG3AzH01bTCInW4",
    "KcHwtHqP2KarZqESgS5Cuv",
    "QPTiDox9sGkHkQFnuuMVVz",
    "LEAuwO1pfiygv0Qy8MKwvF",
    "jsLdri6gPJ7yy6O3enpU4e",
    "nCj19OueZbR8bwn0vBz6j0",
    "F6iF3THpMlmGFJP1AGoMzN",
    "ywlTo6eEX0CYCw5UEsKWyA",
    "PntplFQPhsmftLSzzsikTV",
    "Cpv1XiURwQ7SEzwguwskxE",
    "4BduE0kzP5a3gT6ujRenK8",
    "cQbD34mRlQ1IHrd8nj2Gnc",
    "awm72cPzvtK0sDe0qrZf76",
    "8j0lmVf3dm7HdGJ1V0MBhu",
    "i8dCvX2FUVCtc33UOUsC6X",
    "af8YE2XksKREuOXQ3oTIo3",
    "Oc1C0ic0YHkUciGYgjyRjK",
    "5ow5Tlml6lfZ3EGT5qynZD",
    "C4IIf8tn0v64Q37yWDnID1",
    "Ccy0LGz2ONouw7zltn3OLi",
    "nxd0g5wyPfkEIUczifrLko",
    "g9udcGq4dzmVv77k6JmOI0",
    "veDQii1FzqZqY3IkrxaKb9",
    "9CmddA2VknKlK16BAEmKTn",
    "xBTsnO8XI9cJgn3ICHdFuz",
    "d7ZpOwi7zAYFth2VG3ogfF",
    "uKxJXxIuQdx53DPlDvxnit",
    "UfIJQW2qBVF8fQT4mzymXx",
    "2fUwZqFtMySJf5UEnnH0Dv",
    "iutIQnOD3H8wU5LhyOlngJ",
    "6xZvPF9BbeEc2k7vDs6TGd",
    "3PooltVifT93LMj1Iw8f6N",
    "vb98CBmeXwkDpsnV3t8mqz",
    "SfsCs9xZEL3cCgKmTf2BPj",
    "lcwF7Tk6Y2SUHQcOycCJft",
    "WnbGgzXbeKkRqmMUM7YmnS",
    "NRC03cJzisqn9l77O7dOcZ",
    "t8ZPtL3F0zfEUE8bLoBERx",
    "EiUnODpIhI44h5LBoZVmhS",
    "sMvDzumUJMgZ5SdpYf6SPX",
    "GHr5m7gPmPIjbNXtOO1HoT",
    "ijpljzGKj8Uwp89epPVUza",
    "GT6PmhS2hWnloBZ3exnPYS",
    "hkTSjG7hXoqC2L31VsYpMh",
    "qcqZIEdxND6rkKidIptueN",
    "lnBJjpikNpTXJYWyADeScN",
    "4eZYapPGLduFkX1THmhzdn",
    "rZoq0fe5jzBT8D7m7gGz7z",
    "iT20a5sqM0NI05AMb20gOf",
    "QzVsfTqHqWfB9fRKHDBsy1",
    "88s8rK5YueO1OGZ0B9XJn3",
    "8mthDba9nY61ovTwDnNlEr",
    "99wUJg8F2LnoPlhP6j4yra",
    "uQwQXAYWlCWjnFz3h1hoOG",
    "e0z5VNLhIp3tgA3n7WoSI0",
    "IDgbk25rIvUHbM47iQM873",
    "Z3wCsJJGT1HrRsbgGAblYa",
    "Su3Vm1Q5EaylJBSEHTAzsv",
    "c4VdWh8D9UXYIF05Z6QwKw",
    "dWm98UQIhNYCylP4Uw1AOe",
    "szSbc3oi6BQNrmYzZBabX1",
    "BU4QQSNkpiTkHBhLOp8hby",
    "LFrGh4PvdcFo62ck9HZTkK",
    "uR4HTvPNh8jKT1fJZPuKww",
    "AKAXzjtvIy8DRgbwJ03zxv",
    "Q6LNdMvt2HKFWZPdIQE7vT",
    "vkWaiVHRDM3VjQYvW5ChM8",
    "Mi1FIeIKuFQdqgboiVITIs",
    "7mR071PWTm2VnlcE8mjyes",
    "o6craFalVsxJmBL3nvq2wm",
    "2Nzgmc14i0niJO5iuY5mXu",
    "CLFHGxwqJSzIfDT7uEx9v1",
    "jMiRVcNPk0FiUM5FVhfmvl",
    "etfSnF1NvgmrT9rcQZDBSP",
    "5RFRS9Ppjdhu1ZysI2uCcn",
    "EhmAdenAy536jEojbZyxEa",
    "hxKsszGPIsGO5aYKVVa3Vp",
    "G4UmcWa55G8lXCpnXs5vfT",
    "pQmoRDZugR1ugtyBrxPUtM",
    "qHtSocgUQorAkg9FelISt6",
    "I07fLRnehsBg1tRm1XXTa8",
    "GYkFP59kH6vPeOKoQ6NQsV"
   ],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
